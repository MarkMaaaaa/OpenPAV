
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>Developer tutorial - OpenPAV Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#class-design" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="OpenPAV Documentation" class="md-header__button md-logo" aria-label="OpenPAV Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            OpenPAV Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Developer tutorial
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="OpenPAV Documentation" class="md-nav__button md-logo" aria-label="OpenPAV Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    OpenPAV Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quickstart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quick Start
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model-calibration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Calibration
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../simulation-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simulation Integration
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../vehicle-selection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vehicle Selection
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#class-design" class="md-nav__link">
    <span class="md-ellipsis">
      Class Design
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Class Design">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Workflow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cavworld" class="md-nav__link">
    <span class="md-ellipsis">
      CavWorld
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scenariomanager" class="md-nav__link">
    <span class="md-ellipsis">
      ScenarioManager
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vehiclemanager" class="md-nav__link">
    <span class="md-ellipsis">
      VehicleManager
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#perceptionmanager" class="md-nav__link">
    <span class="md-ellipsis">
      PerceptionManager
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#localizationmanager" class="md-nav__link">
    <span class="md-ellipsis">
      LocalizationManager
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavioragent" class="md-nav__link">
    <span class="md-ellipsis">
      BehaviorAgent
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#v2xmanager" class="md-nav__link">
    <span class="md-ellipsis">
      V2XManager
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>Developer tutorial</h1>

<h2 id="class-design">Class Design</h2>
<p>In this section, we will take a deeper look at the implementation details of several important classes in our OpenCDA framework. For beginners, we encourage you to go through our <a href="tutorial.md">OpenCDA Logic Flow</a> first to understand the general simulation process. This tutorial will emphasize the detailed design logic behind each class and try to give clear descriptions of the core algorithms in each module. We will go through a test example <code>platoon_joining_2lanefree_carla.py</code> and for easy understanding, we have removed some non-core codes to simplify the code flow. To read the complete source code, please refer to our <a href="https://github.com/ucla-mobility/OpenCDA">repo</a>. For details about our cooperative architecture, please refer to our <a href="https://arxiv.org/abs/2107.06260">paper</a>. </p>
<p><strong>Note: this tutorial assume you are using CARLA only instead of Co-simulation.</strong></p>
<h3 id="workflow">Workflow</h3>
<p>The workflow of opencda can be summarized as follows. </p>
<ul>
<li>Write yaml file to define various configurations of the simulation.</li>
<li>Load those configurations into a dictionary <code>scenario_params</code>. For your convenience, we have provided <code>load_yaml</code> for loading the configurations. </li>
<li>Create <code>CavWorld</code> object to store information of registered CAVs and more importantly, to store the shared large models like neural networks. </li>
<li><code>ScenarioManager</code> will use those configurations to set <code>carla.TrafficManager</code> and load customized map if needed.</li>
<li>After the creation of <code>ScenarioManager</code>, users can use its <code>create_vehicle_manager</code> method to spawn Connected Automated Vehicles (CAVs). Internally, each vehicle is managed by a <code>VehicleManager</code>, which will wrap the original <code>carla.Vehicle</code> with other modules such as perception, localization, control, and behavior agent. </li>
<li>Besides single CAVs, there may also be platoons in the traffic. To spawn the platoons, users should use <code>create_platoon_manager</code> method. Similar to the previous single CAV, each member in the platoon will be managed by <code>VehicleManager</code>. In addition,  <code>PlatooningManager</code> is used to maintain the information of all the vehicles in the same platoon. And after the creation of vehicles and platoons, it will return a list of <code>PlatooningManager</code>. </li>
<li>Similar to the process of spawning a single CAV, <code>create_traffic_carla</code> method will spawn background traffic with <code>autopilot=True</code>. </li>
<li>Now all the CAVs and traffic flow are generated, thus we will enter the simulation loop. At the beginning of each simulation
step, <code>scenario_manager.tick()</code> will be called to tick the server. Then all the CAVs will update the surrounding information and execute a single step. The single CAVs may join the platoon in the middle of the travel, so we need to check whether any single CAV has joined a platoon and remove it from the <code>single_cav_list</code> if so.</li>
</ul>
<pre><code class="language-python">from opencda.scenario_testing.utils.customized_map_api import customized_map_helper
def run_scenario(opt, config_yaml):
    scenario_params = load_yaml(config_yaml)
    xodr_path = &quot;path/to/customized_map.xodr&quot;
    # create CAV world
    cav_world = CavWorld(opt.apply_ml)
    # create scenario manager
    scenario_manager = \
    sim_api.ScenarioManager(scenario_params,opt.apply_ml,xodr_path=xodr_path,cav_world=cav_world)
    # create a list of single CAV
    single_cav_list = \
    scenario_manager.create_vehicle_manager(['platooning'],map_helper=customized_map_helper)
    # create platoon members
    platoon_list = scenario_manager.create_platoon_manager(data_dump=False)
    # create background traffic in carla
    traffic_manager, bg_veh_list = scenario_manager.create_traffic_carla()
    # run steps
    while True:
        scenario_manager.tick()
        # update vehicles within platoon
        for platoon in platoon_list:
            platoon.update_information()
            platoon.run_step()
        # update signle CAV
        for i, single_cav in enumerate(single_cav_list):
            # If the CAV is merged into one of the platoon, then we should let platoon manage it.
            # Thus we should remove them from single_cav_list
            if single_cav.v2x_manager.in_platoon():
                single_cav_list.pop(i)
            # If the CAV is not contained in any platoon, then we should update the vehicle.
            else:
                single_cav.update_info()
                control = single_cav.run_step()
                single_cav.vehicle.apply_control(control)
</code></pre>
<h3 id="cavworld">CavWorld</h3>
<p><code>CavWorld</code>  stores CAVs and platoon information. Besides,  it will also store the shared machine learning models, so we don't need to store a separate model for each CAV. <strong>if you plan to use a neural network, this is a good place to load your model and call it in the customized algorithm class to utilize the model.</strong></p>
<pre><code class="language-python">class CavWorld(object):
    def __init__(self, apply_ml=False):
        # store the set of carla.Vehicle ids.
        self.vehicle_id_set = set()
        # store (VehicleManager.vid, VehicleManager) pairs
        self._vehicle_manager_dict = {}
        # store (PlatooningManger.pmid, PlatooningManger) pairs
        self._platooning_dict = {}
        self.ml_manager = None
        if apply_ml:
            # add more ml models here
            self.ml_manager = function_to_load_ML_model()
</code></pre>
<h3 id="scenariomanager">ScenarioManager</h3>
<p><code>ScenarioManager</code>  controls simulation construction, generates background traffic generation, and spawns CAVs. During the initialization stage, it will create the <code>client</code> and load the world with the HD map into the variable <code>self.world</code>. </p>
<pre><code class="language-python">class ScenarioManager:
    def __init__(self, scenario_params,
                   apply_ml,
                   xodr_path=None,
                   town=None,
                   cav_world=None):
        # create the carla.Client
        self.client = carla.Client('localhost', simulation_config['client_port'])

        # load customized map if any
        self.world = load_customized_world(xodr_path, self.client)

        # change the world setting
        setting = self.world.get_settings()
        setting.synchronous_mode = True
        setting.fixed_delta_seconds = simulation_config['fixed_delta_seconds']

        self.world.apply_settings(new_settings)
        self.carla_map = self.world.get_map()
</code></pre>
<p>As we have seen in the workflow section, within this class, there are 3 important methods -- <code>create_vehicle_manager</code>, <code>create_platoon_manager</code>, and <code>create_traffic_carla</code>. </p>
<p>The <code>create_vehicle_manager</code> method will create a list of single CAVs according to the configurations of the yaml files (like the destination, desired speed/limits, etc.).  The <code>create_platoon_manager</code> will create vehicles within platoons and create a platoon manager to group those vehicles. The <code>create_traffic_carla</code> will create background traffic in Carla and configure associated global TrafficManager behaviors. </p>
<p>Now we will introduce each of them:</p>
<ul>
<li>
<p><code>create_vehicle_manager()</code></p>
<p>The CAVs information is stored as a list in the yaml file. Each entry in the list corresponds to a CAV's configuration.This method will pass spawn positions specified in the yaml file to the server and spawn the <code>carla.Vehicle</code> object. For each spawned vehicle, we will wrap it with the class <code>VehicleManager</code>, which essentially supports the localization, perception, platooning behavior, etc. Details about this class can be found in the  <code>VehicleManager</code> section. </p>
<p><code>``python
def create_vehicle_manager(self, application,
                               map_helper=None,
                               data_dump=False):
    # By default, we use lincoln as our cav model.
    cav_vehicle_bp = self.world.get_blueprint_library().find('vehicle.lincoln.mkz2017')
    single_cav_list = []
    # Each entry in the list corresponds to a CAV
    for i, cav_config in enumerate(self.scenario_params['scenario']['single_cav_list']):
        spawn_transform = function_to_load_spawn_position(cav_config)
        cav_vehicle_bp.set_attribute('color', '0, 0, 255')
        vehicle = self.world.spawn_actor(cav_vehicle_bp, spawn_transform)
        # create vehicle manager for each cav
        vehicle_manager = VehicleManager(vehicle, cav_config, application,...)
        self.world.tick()
        vehicle_manager.v2x_manager.set_platoon(None)
                # Set the destination of the vehicle according to the configuration
        destination = carla.Location(x=cav_config['destination'][0],
                                     y=cav_config['destination'][1],
                                     z=cav_config['destination'][2])
        # The</code>update_info` method will call the internal localization module and perception module
        # to update position and detected objects. 
        # Those information is then again passed to the v2x_manager/controller/BehaviorAgent module.
        vehicle_manager.update_info()
        vehicle_manager.set_destination(vehicle_manager.vehicle.get_location(),destination,clean=True)</p>
<pre><code>    single_cav_list.append(vehicle_manager)

return single_cav_list
</code></pre>
<p>```</p>
</li>
<li>
<p><code>create_platoon_manager()</code></p>
<p>This method will first loop over the predefined platoon list. For each platoon, we will create a <code>PlatooningManager</code> object to group all the vehicles within the platoon. In the current version, we assume the first vehicle in the platoon is the lead vehicle. After creating all of the vehicles of each platoon, it will return a list of <code>PlatooningManager</code>. As a result, we can control the behavior of each platoon via a single line of code without worrying about details of how each vehicle will react. </p>
<p><code>python
def create_platoon_manager(self, map_helper=None, data_dump=False):    
    platoon_list = []
    self.cav_world = CavWorld(self.apply_ml)
    # we use lincoln as default choice since our UCLA mobility lab use the
    # same car
    cav_vehicle_bp = \
    self.world.get_blueprint_library().find('vehicle.lincoln.mkz2017')
    # create platoons
    for i, platoon in enumerate(self.scenario_params['scenario']['platoon_list']):
        platoon_manager = PlatooningManager(platoon, self.cav_world)
        for j, cav in enumerate(platoon['members']):
            # Similar as spawning single CAV, we need to create its start location (spawn_transform)
            # and set its color etc. 
            ...
            vehicle = self.world.spawn_actor(cav_vehicle_bp,spawn_transform)
            # create vehicle manager for each cav
            vehicle_manager = VehicleManager(vehicle, cav, ['platooning'],
                      self.carla_map, self.cav_world,
                      current_time=self.scenario_params['current_time'],
                      data_dumping=data_dump)
            # add the vehicle manager to platoon
            if j == 0:
                platoon_manager.set_lead(vehicle_manager)
            else:
                platoon_manager.add_member(vehicle_manager, leader=False)
            self.world.tick()
        destination = carla.Location(x=platoon['destination'][0],
                                     y=platoon['destination'][1],
                                     z=platoon['destination'][2])
        platoon_manager.set_destination(destination)
        platoon_manager.update_member_order()
        platoon_list.append(platoon_manager)
    return platoon_list</code></p>
</li>
<li>
<p><code>create_traffic_carla()</code>
    This method will create the <code>carla.TrafficManager</code> and set associated parameters. Afterward, it will spawn the background vehicles. For spawning the vehicles, there are two options -- <code>spawn_vehicle_by_range</code> and <code>spawn_vehicles_by_list</code>. Depending on the way you configure them, the code will choose the associated one to do the task. Here for illustration, we use the <code>spawn_vehicles_by_list</code>. </p>
<p>```python
def create_traffic_carla(self):
    traffic_config = self.scenario_params['carla_traffic_manager']
    # get carla.TrafficManager
    tm = self.client.get_trafficmanager()
    tm.set_global_distance_to_leading_vehicle(
      traffic_config['global_distance'])
    tm.set_synchronous_mode(traffic_config['sync_mode'])
    tm.set_osm_mode(traffic_config['set_osm_mode'])
    tm.global_percentage_speed_difference(traffic_config['global_speed_perc'])</p>
<pre><code>bg_list = spawn_vehicles_by_list(tm, traffic_config, bg_list)

return tm, bg_list
</code></pre>
<p>```</p>
<p>The <code>spawn_vehicles_by_list</code> has similar structure as <code>create_vehicle_manager</code> with the support of randomness of the vehicles' apperance and colors. Notice that, different from CAVs, we will set autopilot to <code>True</code> for those background traffic and we will return a list of <code>carla.Vehicle</code> instead of the <code>VehicleManager</code>  used in the <code>Create_vehicle_manager</code>. </p>
</li>
</ul>
<h3 id="vehiclemanager">VehicleManager</h3>
<p>This class will wrap the original <code>carla.Vehicle</code> object and associate the vehicles with various modules including localization, perception, control, agent and V2Xmanager. </p>
<pre><code class="language-python">class VehicleManager(object):
    def __init__(self, vehicle, config_yaml, application, 
                 carla_map, cav_world, current_time='',data_dumping=False):

        # an unique uuid for this vehicle
        self.vid = str(uuid.uuid1())
        self.vehicle = vehicle
        self.carla_map = carla_map

        # retrieve the configure for different modules
        sensing_config = config_yaml['sensing']
        behavior_config = config_yaml['behavior']
        control_config = config_yaml['controller']
        v2x_config = config_yaml['v2x']

        # v2x module
        self.v2x_manager = V2XManager(cav_world, v2x_config)
        # localization module
        self.localizer = LocalizationManager(vehicle, sensing_config['localization'], carla_map)
        # perception module
        self.perception_manager = PerceptionManager(
            vehicle, sensing_config['perception'], cav_world.ml_manager, data_dumping)
        # BehaviorAgent
        self.agent = BehaviorAgent(vehicle, carla_map, behavior_config)
        # Control module
        self.controller = ControlManager(config_yaml['controller'])
        cav_world.update_vehicle_manager(self)
</code></pre>
<p>The localization module will spawn the location-related sensor actors such as GNSS and IMU. And within the localization module, it will use the Kalman Filter to keep track of the vehicle's location and speed. </p>
<p>The perception module will spawn perception-related sensors such as cameras and LiDAR. If the ML model is applied (<code>self.active=True</code>), it will also detect the surrounding vehicles with the default Yolov5 detector. If the ML model is not applied (<code>self.active=False</code>), it will use server information directly and use the LiDAR to filter out vehicles out of the range. </p>
<p>The agent module is a key component in our architecture. It will utilize the perception and localization information to produce the planned trajectory that should be passed into the downstream controller,  so that the desired destination can be reached.  There are two types of <strong>agents</strong> in our released codebase -- <code>BehaviorAgent</code> and <code>PlatooningBehaviorAgent</code>. <code>BehaviorAgent</code> is designed for the single-vehicle while <code>PlatooningBehaviorAgent</code> has special methods to deal with the platooning behaviors. We will talk more about those classes in their sections. </p>
<p>There are several commonly used methods within this class. Here we will briefly talk about each of them. </p>
<ul>
<li>
<p><code>set_destination</code> </p>
<p>It will call the agent's <code>set_destination</code> method to set the destination and prepare the global planner and local planner. Please refer to the localization module for details.</p>
</li>
<li>
<p><code>update_info</code></p>
<p>It will call the localization module to get the latest position and velocity. Besides, it will call the perception module to get a list of obstacle vehicles. Afterward, it will update the <code>agent</code> and <code>controller</code> as well to inform them about those changes. </p>
</li>
<li>
<p><code>run_step</code></p>
<p>It will take in the <code>target_speed</code> and call <code>agent.run_step(target_speed)</code> to get the ideal speed and location that we want to reach in the next time frame. After that, it will pass the speed and location to the controller to generate the actual control command. And it will return the control command to the caller. </p>
</li>
<li>
<p><code>destroy</code></p>
<p>It will destroy the vehicle and associated sensors. </p>
</li>
</ul>
<h3 id="perceptionmanager">PerceptionManager</h3>
<p><code>PerceptionManager</code> will spawn perception-related sensors including camera, LiDAR, and Semantic LiDAR. In this class, there are also many attributes for visualization. For code simplicity, we have removed them from our sample code here. </p>
<pre><code class="language-python">class PerceptionManager:
    def __init__(self, vehicle, config_yaml, cav_world, data_dump=False):

                self.activate = config_yaml['activate']
        self.rgb_camera = []
        mount_position = ['front', 'right', 'left']
        for i in range(self.camera_num):
            self.rgb_camera.append(CameraSensor(vehicle, mount_position[i]))
        self.lidar = LidarSensor(vehicle, config_yaml['lidar'])
        if data_dump:
            self.semantic_lidar = SemanticLidarSensor(vehicle,
                                                      config_yaml['lidar'])
        # count how many steps have been passed
        self.count = 0
        # ego position
        self.ego_pos = None

        # the dictionary contains all objects
        self.objects = {}
</code></pre>
<p>For the current version, the main function we provide is detection. And there are two important methods in this class -- <code>detect</code> and <code>retrieve_traffic_lights</code>.</p>
<ul>
<li>
<p><code>detect</code></p>
<p>It will detect surrounding vehicles by using specified model.  If <code>self.activate</code> flag is set, it will use the Yolov5 stored in the <code>CavWorld</code> to detect the obstacle vehicles. Otherwise, it will use the server information directly. </p>
<p><code>python
def detect(self, ego_pos):
    self.ego_pos = ego_pos
    objects = {'vehicles': [],
    'traffic_lights': []}
    if not self.activate:
            objects = self.deactivate_mode(objects)
    else:
            objects = self.activate_mode(objects)
    self.count += 1
    return objects</code></p>
</li>
<li>
<p><code>retrieve_traffic_lights</code> </p>
<p>It will retrieve the traffic light states directly from the server. Thus in current version, we use ground truth to get the traffic light data. We may consider adding customized traffic light detection module in the next version. Researchers can also replace this method with their own traffic light detection algorithm by simply rewriting the following method. </p>
<p><code>python
def retrieve_traffic_lights(self, objects):
    world = self.vehicle.get_world()
    tl_list = world.get_actors().filter('traffic.traffic_light*')
    objects.update({'traffic_lights': []})
    for tl in tl_list:
        distance = self.dist(tl)
        if distance &lt; 50:
            traffic_light = TrafficLight(tl.get_location(),
                         tl.get_state())
            objects['traffic_lights'].append(traffic_light)
    return objects</code></p>
</li>
</ul>
<h3 id="localizationmanager">LocalizationManager</h3>
<p>The <code>LocalizationManager</code> will spawn location-related sensors including GNSS and IMU. And it will use the Kalman Filter to keep track of cars' location and speed. Though we read the speed and yaw angle directly from the server, to simulate the real world's uncertainty, noise is also added to the data retrieved from the server. And user can control the noise level by changing the parameters like <code>speed_stddev</code> in <code>yaml</code> file. </p>
<pre><code class="language-python">class LocalizationManager(object):
    def __init__(self, vehicle, config_yaml, carla_map):

        self.vehicle = vehicle
        self.activate = config_yaml['activate']
        self.map = carla_map
        self.geo_ref = self.map.transform_to_geolocation(
            carla.Location(x=0, y=0, z=0))

        # speed and transform and current timestamp
        self._ego_pos = None
        self._speed = 0

        # history track
        self._ego_pos_history = deque(maxlen=100)
        self._timestamp_history = deque(maxlen=100)

        self.gnss = GnssSensor(vehicle, config_yaml['gnss'])
        self.imu = ImuSensor(vehicle)

        # heading direction noise
        self.heading_noise_std = \
            config_yaml['gnss']['heading_direction_stddev']
        self.speed_noise_std = config_yaml['gnss']['speed_stddev']

        self.dt = config_yaml['dt']
        # Kalman Filter
        self.kf = KalmanFilter(self.dt)


</code></pre>
<h3 id="behavioragent">BehaviorAgent</h3>
<p>The behavior agent will collect the information from the perception and localization module and use this information to produce the planned trajectory, which will be later passed to the controller.  There are two types of planner within the agent -- local planner and global planner. The global planner will generate the global path, considering the static map. The local planner will utilize the new perceived information to modify the global plan so that it can avoid dynamic obstacles and obey traffic rules. </p>
<pre><code class="language-python">class BehaviorAgent(object):
    def __init__(self, vehicle, carla_map, config_yaml):
        # Load various parameters 
        ...
        self._sampling_resolution = config_yaml['sample_resolution']

        # collision checker
        self._collision_check = CollisionChecker(time_ahead=config_yaml['collision_time_ahead'])

        # used to indicate whether a vehicle is on the planned path
        self.hazard_flag = False

        # route planner related
        self._global_planner = None
        self.start_waypoint = None
        self.end_waypoint = None

        # intersection agent related
        self.light_state = &quot;Red&quot;
        self.light_id_to_ignore = -1

        # trajectory planner
        self._local_planner = LocalPlanner(self, carla_map, config_yaml['local_planner'])
        # special behavior rlated
        self.car_following_flag = False
        # lane change allowed flag
        self.lane_change_allowed = True
        # destination temp push flag
        self.destination_push_flag = False
        # white list of vehicle managers that the cav does not consider as
        # obstacles
        self.white_list = []
        self.obstacle_vehicles = []
</code></pre>
<ul>
<li>
<p><code>update_information</code>
    The <code>VehicleManager</code> will call <code>agent.update_information</code> to update the position and speed as well as the detected objects. Afterward, the agent will update the local planner with the new speed/location information. For the detected objects, it may contain the vehicles that are about to join the platooning and those vehicles should be managed by the platooning manager. Thus we should remove those vehicles from the <code>objects</code> like shown below. Besides, we will also update the traffic light state here. </p>
<p>```python
def update_information(self, ego_pos, ego_speed, objects):
    # update localization information
    self._ego_speed = ego_speed
    self._ego_pos = ego_pos
    self.break_distance = self._ego_speed / 3.6 * self.emergency_param</p>
<pre><code># update the localization info to trajectory planner
self.get_local_planner().update_information(ego_pos, ego_speed)
# The white list contains all position of target platoon member for joining. 
# Those vehicles should be managed by platooning manager. Thus we should remove them.
# Right now the white_list_match function will associate the vehicles 
# based on their lane_id and location.
obstacle_vehicles = objects['vehicles']
self.obstacle_vehicles = self.white_list_match(obstacle_vehicles)

# update the debug helper
self.debug_helper.update(ego_speed, self.ttc)
if self.ignore_traffic_light:
    self.light_state = "Green"
else:
    # This method also includes stop signs and intersections.
    self.light_state = str(self.vehicle.get_traffic_light_state())
</code></pre>
<p>```</p>
</li>
<li>
<p><code>set_destination</code></p>
<p>Given the start location and end location, it will find the closest waypoints in the map to each of them. And we will use those 2 waypoints as the starting and end node. We will use the following code to make sure the starting node is always in front of the vehicle.</p>
<p><code>python
_, angle = cal_distance_angle(self.start_waypoint.transform.location, cur_loc, cur_yaw)
while angle &gt; 90:
    self.start_waypoint = self.start_waypoint.next(1)[0]
    _, angle = cal_distance_angle(
    self.start_waypoint.transform.location, cur_loc, cur_yaw)</code></p>
<p>And we will call <code>self._trace_route</code> to find the list of waypoints from the starting node to the end node. Then, we will store the route into the buffer <code>self.waypoints_queue</code>. </p>
</li>
<li>
<p><code>_trace_route</code></p>
<p>This method will find the path from the <code>start_waypoint</code> to the <code>end_waypoint</code>. If the global plan has not been set before, it will load the <code>GlobalRoutePlanner</code> first. The algorithm for searching can be summarized as follows.</p>
<ul>
<li>Given the <code>start_waypoint</code>, find the edge in the original graph containing this waypoint's location (achieved through <code>GlobalRoutePlanner._localize</code>).  And use the start node of the edge as the actual search origin. Through the same process, we can find the actual destination based on the provided <code>end_point</code>. </li>
<li>Use A* algorithm to find the path from origin to destination.  The path will contain a list of waypoints. The waypoint is either the start or end of a lane segment. Add the destination at the end of the path.</li>
<li>For each of the traversed edges in the path, we can find the corresponding turn decision (it is called RoadOption, e.g. lanefollow, left, right turn, etc.). See <code>RoadOption</code> class for complete definition. Then, loop over the edges,<ul>
<li>If the turn decision of the edge is lanefollow or void, then also add the <code>edge['path']</code> with associated RoadOption to the path.</li>
<li>Else, only add current_waypoint and a point in the target lane with a certain distance away. (see <code>GlobalRoutePlanner.trace_route</code> for details.)</li>
</ul>
</li>
<li>Now we have a list of (waypoint, RoadOption) pairs. </li>
<li>Add the pairs to the <code>waypoints_queue</code>. If the <code>clean</code> flag is on, also
 update the <code>_waypoint_buffer</code>. </li>
</ul>
</li>
<li>
<p><code>run_step</code> </p>
<p>This method contains the function of behavior regulation and trajectory generation. To obey the traffic rules and consider the dynamic road elements, we have designed the following cases. Each case will have distinct driving behavior.</p>
<ul>
<li>
<p><strong>Destination arrived</strong></p>
<p>If the current location is near a radius of the destination ($10$ meters by default), the vehicle has arrived at the destination and we will exit the agent. </p>
</li>
<li>
<p><strong>Red traffic light</strong></p>
<p>If the vehicle is in the junction and the traffic light is red, then return a target speed of 0.  Here we also consider the case when the car has moved to the center of the junction and the traffic light turns green at the current timestamp. In this case, it is very dangerous for the car to stop at the center of the junction. Thus we will use <code>light_id_to_ignore</code> to ignore this red light so that the car will continue moving. See <a href="https://github.com/ucla-mobility/OpenCDA/blob/555aeab2bac7471d9400c51aea9c76741954b54b/opencda/core/plan/behavior_agent.py#L352">code</a> for details</p>
</li>
<li>
<p><strong>Lane change behaviors</strong></p>
<ul>
<li>If the car is near the intersection, for safety concerns, the overtake and lane change are not allowed.</li>
<li>If the curvature of the road is high, the lane change is disabled. </li>
<li>If a lane change is allowed and the global plan indeed outputs a lane change path, then do a collision check to see if the target lane is free. </li>
</ul>
</li>
<li>
<p><strong>Car following</strong></p>
<p>If the car following mode is on, follow the leading car.</p>
</li>
<li>
<p><strong>Normal Mode</strong></p>
<p>For the normal mode, we will sample points along the path and return the target speed and target location. </p>
</li>
</ul>
</li>
</ul>
<h3 id="v2xmanager">V2XManager</h3>
<p><code>V2XManager</code> is used to receive information from other CAVs and deliver ego information to them. The class attributes <code>ego_pos</code> and <code>ego_spped</code> are both deque type. Such data type is used to simulate the signal lagging during communication, e.g., <code>ego_pos[-3]</code> represents there is a lag of 2 time steps (<code>ego_pos[-1]</code> represents the most recent one).</p>
<pre><code class="language-python">class V2XManager(object):
    def __init__(self, cav_world, config_yaml, vid):
        # if disabled, no cooperation will be operated
        self.cda_enabled = config_yaml['enabled']
        self.communication_range = config_yaml['communication_range']

        # found CAVs nearby
        self.cav_nearby = {}

        # used for cooperative perception.
        self._recieved_buffer = {}

        # used for platooning communication
        self.platooning_plugin = PlatooningPlugin(
            self.communication_range, self.cda_enabled)

        self.cav_world = weakref.ref(cav_world)()

        # ego position buffer. use deque so we can simulate lagging
        self.ego_pos = deque(maxlen=100)
        self.ego_spd = deque(maxlen=100)
        # used to exclude the cav self during searching
        self.vid = vid

        # check if lag or noise needed to be added during communication
        self.loc_noise = 0.0
        self.yaw_noise = 0.0
        self.speed_noise = 0.0
        self.lag = 0

        if 'loc_noise' in config_yaml:
            self.loc_noise = config_yaml['loc_noise']
        if 'yaw_noise' in config_yaml:
            self.yaw_noise = config_yaml['yaw_noise']
        if 'speed_noise' in config_yaml:
            self.speed_noise = config_yaml['speed_noise']
        if 'lag' in config_yaml:
            self.lag = config_yaml['lag']
</code></pre>
<ul>
<li><code>update_info</code></li>
</ul>
<p>This method updates the ego vehicle's speed and position and passes the updated information to different application plugins. Also, this method searches all of the neighboring vehicles within range. To search the vehicles, we need to retrieve a list of registered vehicles' information from <code>CavWorld</code>. For each vehicle in the list, we compute its distance to the ego vehicle. If the distance is less than the threshold (<code>communication_range</code>), we consider it as a neighboring vehicle.  </p>
<p>```python
    def update_info(self, ego_pos, ego_spd):
        self.ego_pos.append(ego_pos)
        self.ego_spd.append(ego_spd)
        self.search()</p>
<pre><code>    # the ego pos in platooning_plugin is used for self-localization,
    # so we shouldn't add noise or lag.
    self.platooning_plugin.update_info(ego_pos, ego_spd)
</code></pre>
<p>```</p>
<ul>
<li><code>get_ego_pos</code> </li>
</ul>
<p>This method adds noise and lags to the ego pose and then delivers to other CAVs.</p>
<p>```python
    def get_ego_pos(self):
         # add lag
        ego_pos = self.ego_pos[0] if len(self.ego_pos) &lt; self.lag else \
            self.ego_pos[np.random.randint(-1 - int(abs(self.lag)), 0)]</p>
<pre><code>    x_noise = np.random.normal(0, self.loc_noise) + ego_pos.location.x
    y_noise = np.random.normal(0, self.loc_noise) + ego_pos.location.y
    z = ego_pos.location.z
    yaw_noise = np.random.normal(0, self.yaw_noise) + ego_pos.rotation.yaw

    noise_location = carla.Location(x=x_noise, y=y_noise, z=z)
    noise_rotation = carla.Rotation(pitch=0, yaw=yaw_noise, roll=0)

    processed_ego_pos = carla.Transform(noise_location, noise_rotation)

    return processed_ego_pos
</code></pre>
<p>```</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
    
  </body>
</html>